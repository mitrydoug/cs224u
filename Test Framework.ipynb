{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "import pandas as pd\n",
    "\n",
    "from data import RandomData, AmazonBooks, ToyData, MovieLensData\n",
    "from model import RandomModel, CombinedMeanModel, ItemItemCollaborationModel\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading preprocessed dataset from disk\n"
     ]
    }
   ],
   "source": [
    "ds = MovieLensData(min_user_ratings=5).get_dataset(verbose=True)\n",
    "train = ds['train']\n",
    "val = ds['val']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2702933, 2754434, 5097362)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(len(ds['test']['user_product_ratings']),\n",
    " len(ds['val']['user_product_ratings']),\n",
    " len(ds['train']['user_product_ratings']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4.0    1435242\n",
       "3.0    1043209\n",
       "5.0    1021570\n",
       "3.5     435754\n",
       "4.5     427696\n",
       "2.0     297769\n",
       "1.0     162929\n",
       "2.5     150745\n",
       "0.5      67362\n",
       "1.5      55086\n",
       "Name: rating, dtype: int64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train['user_product_ratings'].rating.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "179307"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(set(ds['train']['user_product_ratings'].user_id))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "214990"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(set(ds['val']['user_product_ratings'].user_id))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(11046, 11120, 10640)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(len(ds['test']['product_descriptions']),\n",
    " len(ds['val']['product_descriptions']),\n",
    " len(ds['train']['product_descriptions']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(73038, 72454, 88503)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(len(ds['test']['product_reviews']),\n",
    " len(ds['val']['product_reviews']),\n",
    " len(ds['train']['product_reviews']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x1a17b3b828>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1a17b3b1d0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "ds['train']['user_product_ratings'].groupby('user_id')['rating'].count().hist(log=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Accuracy Metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mean_squared_error(pred, ground_truth):\n",
    "    return np.mean((pred - ground_truth) ** 2.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def accuracy(pred, ground_truth):\n",
    "    return (np.round(pred) == ground_truth).sum() / float(len(pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_model(model, train, val, loss_fn):\n",
    "    model.fit(train)\n",
    "    train_up_rat = train['user_product_ratings']\n",
    "    val_up_rat = val['user_product_ratings'].copy()\n",
    "    val_up_rat['pred'] = model.predict(val_up_rat[['user_id', 'product_id']])\n",
    "    \n",
    "    train_users = set(train['user_product_ratings'].user_id)\n",
    "    train_products = set(train['user_product_ratings'].product_id)\n",
    "    \n",
    "    train_loss = loss_fn(model.predict(train_up_rat[['user_id', 'product_id']]),\n",
    "                         train_up_rat.rating)\n",
    "    \n",
    "    val_loss = loss_fn(model.predict(val_up_rat[['user_id', 'product_id']]),\n",
    "                       val_up_rat.rating)\n",
    "    \n",
    "    A_data = val_up_rat[val_up_rat.user_id.isin(train_users) & \n",
    "                        val_up_rat.product_id.isin(train_products)]\n",
    "    A_loss = loss_fn(A_data.pred, A_data.rating)\n",
    "    \n",
    "    B_data = val_up_rat[~val_up_rat.user_id.isin(train_users) &\n",
    "                        val_up_rat.product_id.isin(train_products)]\n",
    "    B_loss = loss_fn(B_data.pred, B_data.rating)\n",
    "    \n",
    "    C_data = val_up_rat[val_up_rat.user_id.isin(train_users) &\n",
    "                        ~val_up_rat.product_id.isin(train_products)]\n",
    "    C_loss = loss_fn(C_data.pred, C_data.rating)\n",
    "    \n",
    "    D_data = val_up_rat[~val_up_rat.user_id.isin(train_users) &\n",
    "                        ~val_up_rat.product_id.isin(train_products)]\n",
    "    D_loss = loss_fn(D_data.pred, D_data.rating)\n",
    "    \n",
    "    print('\\n'.join(\n",
    "        ['     Products',\n",
    "         '    -----------',\n",
    "         '   |       |   |  (A.x) TRAIN SET',\n",
    "         ' U | (A.x) |   |  (A.o) VAL CELL HOLDOUT',\n",
    "         ' s | (A.o) |(C)|    (B) VAL USER HOLDOUT',\n",
    "         ' e |       |   |    (C) VAL PRODUCT HOLDOUT',\n",
    "         ' r |       |   |    (D) VAL PRODUCT & USER HOLDOUT',\n",
    "         ' s |-------|---|    (V) VAL SET',\n",
    "         '   |  (B)  |(D)|',\n",
    "         '    -----------',\n",
    "         '================================',\n",
    "         '']))\n",
    "    \n",
    "    def stats(data, loss, lbl):\n",
    "        print(lbl)\n",
    "        print(f'      Number of users: {len(set(data.user_id))}')\n",
    "        print(f'      Number of proucts: {len(set(data.product_id))}')\n",
    "        print(f'      Number of ratings: {len(data)}')\n",
    "        print(f'      loss: {loss}\\n')\n",
    "    stats(train_up_rat, train_loss, '(A.x) TRAIN SET')\n",
    "    stats(val_up_rat, val_loss, '  (V) VAL SET')\n",
    "    stats(A_data, A_loss, '(A.o) VAL CELL HOLDOUT')\n",
    "    stats(B_data, B_loss, '  (B) VAL USER HOLDOUT')\n",
    "    stats(C_data, C_loss, '  (C) VAL PRODUCT HOLDOUT')\n",
    "    stats(D_data, D_loss, '  (D) VAL PRODUCT & USER HOLDOUT')\n",
    "    return val_loss, A_loss, B_loss, C_loss, D_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'users' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-14-beeaa2f341d9>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mItemItemCollaborationModel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0m_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mevaluate_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmean_squared_error\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-13-845c6dec693b>\u001b[0m in \u001b[0;36mevaluate_model\u001b[0;34m(model, train, val, loss_fn)\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[0mtrain_up_rat\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'user_product_ratings'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0mval_up_rat\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mval\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'user_product_ratings'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m     \u001b[0mval_up_rat\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'pred'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mval_up_rat\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'user_id'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'product_id'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m     \u001b[0mtrain_users\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'user_product_ratings'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0muser_id\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Documents/stanford/junior/cs224u/cs224u/cs224u_project/model.py\u001b[0m in \u001b[0;36mpredict\u001b[0;34m(self, users_products, item_item)\u001b[0m\n\u001b[1;32m    193\u001b[0m             \u001b[0mproduct_id\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrow\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'product_id'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    194\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 195\u001b[0;31m             \u001b[0mcollab\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcollab_user_product\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0muser_id\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mproduct_id\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    196\u001b[0m             \u001b[0mresults\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcollab\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    197\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mSeries\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresults\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindex\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0musers_products\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Documents/stanford/junior/cs224u/cs224u/cs224u_project/model.py\u001b[0m in \u001b[0;36mcollab_user_product\u001b[0;34m(self, user, product, num_neighbors)\u001b[0m\n\u001b[1;32m    153\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    154\u001b[0m         \u001b[0muser_pqueue\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mQ\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mPriorityQueue\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 155\u001b[0;31m         \u001b[0;32mfor\u001b[0m \u001b[0mu\u001b[0m \u001b[0;32min\u001b[0m \u001b[0musers\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    156\u001b[0m             \u001b[0muser_pqueue\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mput\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpearson_corr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0muser\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mu\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mu\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    157\u001b[0m         \u001b[0muser_avg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0muser_mean_rating\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0muser\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'users' is not defined"
     ]
    }
   ],
   "source": [
    "model = ItemItemCollaborationModel()\n",
    "_ = evaluate_model(model, train, val, mean_squared_error)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = SimpleMeanModel()\n",
    "_ = evaluate_model(model, train, val, mean_squared_error)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'UserMeanModel' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-15-f414bf589fd6>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mUserMeanModel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0m_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mevaluate_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmean_squared_error\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'UserMeanModel' is not defined"
     ]
    }
   ],
   "source": [
    "model = UserMeanModel()\n",
    "_ = evaluate_model(model, train, val, mean_squared_error)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'ProductMeanModel' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-16-83cad5b9b4a5>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mProductMeanModel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0m_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mevaluate_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmean_squared_error\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'ProductMeanModel' is not defined"
     ]
    }
   ],
   "source": [
    "model = ProductMeanModel()\n",
    "_ = evaluate_model(model, train, val, mean_squared_error)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     Products\n",
      "    -----------\n",
      "   |       |   |  (A.x) TRAIN SET\n",
      " U | (A.x) |   |  (A.o) VAL CELL HOLDOUT\n",
      " s | (A.o) |(C)|    (B) VAL USER HOLDOUT\n",
      " e |       |   |    (C) VAL PRODUCT HOLDOUT\n",
      " r |       |   |    (D) VAL PRODUCT & USER HOLDOUT\n",
      " s |-------|---|    (V) VAL SET\n",
      "   |  (B)  |(D)|\n",
      "    -----------\n",
      "================================\n",
      "\n",
      "(A.x) TRAIN SET\n",
      "      Number of users: 3381\n",
      "      Number of proucts: 9088\n",
      "      Number of ratings: 21175\n",
      "      loss: 0.30779498747098\n",
      "\n",
      "  (V) VAL SET\n",
      "      Number of users: 3404\n",
      "      Number of proucts: 6431\n",
      "      Number of ratings: 11588\n",
      "      loss: 1.0806971070500666\n",
      "\n",
      "(A.o) VAL CELL HOLDOUT\n",
      "      Number of users: 1491\n",
      "      Number of proucts: 1827\n",
      "      Number of ratings: 2195\n",
      "      loss: 1.2075150970715742\n",
      "\n",
      "  (B) VAL USER HOLDOUT\n",
      "      Number of users: 619\n",
      "      Number of proucts: 2424\n",
      "      Number of ratings: 3175\n",
      "      loss: 1.1184449993859649\n",
      "\n",
      "  (C) VAL PRODUCT HOLDOUT\n",
      "      Number of users: 2117\n",
      "      Number of proucts: 1912\n",
      "      Number of ratings: 4131\n",
      "      loss: 0.9888275083994955\n",
      "\n",
      "  (D) VAL PRODUCT & USER HOLDOUT\n",
      "      Number of users: 685\n",
      "      Number of proucts: 1587\n",
      "      Number of ratings: 2087\n",
      "      loss: 1.0717360460830918\n",
      "\n"
     ]
    }
   ],
   "source": [
    "model = CombinedMeanModel()\n",
    "_ = evaluate_model(model, train, val, mean_squared_error)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<module 'model' from '/Users/gili/Documents/stanford/junior/cs224u/cs224u/cs224u_project/model.py'>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import model\n",
    "import imp\n",
    "imp.reload(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "def load_glove(glove_data_file):\n",
    "        words = pd.read_table(glove_data_file, sep=\" \", index_col=0, header=None, quoting=csv.QUOTE_NONE)\n",
    "        return words\n",
    "\n",
    "def convert_word_to_vec(model, w, embed_size, verbose=True):\n",
    "    if w in model.index:\n",
    "        if verbose: \n",
    "            print(\"found\")\n",
    "        return model.loc[w].as_matrix()\n",
    "    else:\n",
    "        if verbose: \n",
    "            print(\"not found\")\n",
    "        return np.random.normal(0, 0.7, embed_size)\n",
    "\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "def randomly_sample(model):\n",
    "    all_words = []\n",
    "    count = 0\n",
    "    for w in model.index:\n",
    "        all_words.append(model.loc[w].as_matrix())\n",
    "        if count > 1000:\n",
    "            plt.hist(np.array(all_words).flatten())\n",
    "            return\n",
    "        count += 1\n",
    "    \n",
    "import os\n",
    "def create_vsm(corpus, embed_size=50, glove_file_path='glove.6B'):\n",
    "    vsm_list = []\n",
    "    vocab = set(corpus)\n",
    "    assert(embed_size == 50 or embed_size==100)\n",
    "    glove_file = os.path.join(glove_file_path, 'glove.6B.%dd.txt' % embed_size)\n",
    "    model = None\n",
    "    model = load_glove(glove_file)\n",
    "    if model is not None:\n",
    "        for word in vocab:\n",
    "            word_as_vec = convert_word_to_vec(model, word, embed_size)\n",
    "            vsm_list.append(word_as_vec)\n",
    "    return np.array(vsm_list)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "found\n",
      "found\n",
      "found\n",
      "found\n",
      "found\n",
      "found\n",
      "found\n",
      "found\n",
      "found\n",
      "found\n",
      "found\n",
      "not found\n",
      "not found\n",
      "found\n",
      "found\n",
      "found\n",
      "found\n",
      "not found\n",
      "[[ 7.2607e-02  7.0889e-01  4.2583e-01 -5.6344e-02 -2.7468e-01  1.0245e+00\n",
      "  -3.4179e-01 -8.0244e-01 -1.7076e-01 -3.4955e-01 -3.3893e-02  1.5975e-01\n",
      "   1.1722e-01  4.6308e-01 -2.1898e-01 -1.1145e-01 -2.5906e-01 -1.6977e-01\n",
      "  -6.1767e-01 -2.5274e-01  6.7205e-01 -2.2908e-01 -1.5565e-01  8.5560e-03\n",
      "   2.2689e-01 -1.3908e-01 -5.4157e-02  1.0742e-01  2.3514e-01 -8.9140e-02\n",
      "   1.4436e-01  7.9394e-01 -5.7136e-01 -2.5193e-01 -3.9158e-01 -1.3934e-01\n",
      "  -3.8139e-01 -9.4135e-02  2.6057e-01  7.7475e-02 -1.4822e-01 -4.1464e-01\n",
      "   2.5563e-03  4.4005e-02 -7.7818e-01 -1.5953e-01 -6.1808e-02 -3.9439e-01\n",
      "  -5.2755e-01 -6.2012e-01  7.1911e-01 -1.0982e-02  1.1115e+00  8.0687e-01\n",
      "  -3.1538e-01 -1.6293e+00  3.3266e-02 -6.3853e-02  6.1646e-01 -1.0547e-01\n",
      "   3.5890e-01  1.4457e+00 -4.6421e-01 -7.5587e-01  6.4232e-01 -1.6544e-01\n",
      "   9.0204e-01  1.5494e-01 -2.8529e-02 -7.4347e-01 -5.7556e-01  4.2777e-01\n",
      "   1.2496e-01 -9.3405e-01  7.1049e-01  5.1595e-01 -1.4973e-02  4.3813e-01\n",
      "  -5.4513e-01 -1.4966e-01  1.3210e-02 -1.4461e+00 -5.0183e-01 -7.7890e-01\n",
      "  -1.8105e+00  4.3226e-01 -2.1408e-01 -6.7476e-01  5.6730e-01 -3.7571e-01\n",
      "  -3.0600e-01  6.3000e-01  1.1221e-01  3.7959e-01 -4.6608e-01 -3.0273e-02\n",
      "  -8.4953e-01 -4.6244e-01 -2.6510e-01  5.7559e-01]\n",
      " [-1.9104e-01  1.7601e-01  3.6920e-01 -5.0323e-01 -4.7561e-01  1.5798e-01\n",
      "  -1.1679e-01  2.1052e-01  3.2652e-01  1.2194e-01  9.0944e-02  2.6089e-01\n",
      "   7.6294e-01  6.9673e-04 -5.0001e-02 -4.4853e-01  3.6239e-01  5.6345e-01\n",
      "  -6.8702e-01  3.3237e-01  3.1285e-01 -1.4207e-01  3.5327e-01 -1.6426e-01\n",
      "  -1.0693e-01  7.7786e-02 -1.7704e-01 -9.2897e-01  1.4680e-01 -1.3585e-01\n",
      "   2.5682e-01  6.6019e-01 -3.5569e-01  2.1838e-01  3.8173e-01  5.4337e-01\n",
      "   1.0197e-01  3.5230e-01 -2.5510e-01 -1.5155e-01 -6.7434e-01  1.6903e-01\n",
      "   1.6413e-01 -5.3843e-01 -1.7457e-01 -2.8539e-01  7.4044e-01 -6.7533e-01\n",
      "  -2.3382e-01 -1.3599e+00  3.0225e-01 -1.4968e-01  2.7043e-01  1.1979e+00\n",
      "  -2.9556e-01 -2.5395e+00  1.0303e-03 -2.6272e-01  1.8303e+00  8.0008e-01\n",
      "  -3.5691e-01  5.6578e-01 -5.5040e-01  7.0845e-02  1.4275e+00  9.0160e-02\n",
      "   7.8420e-01  7.8490e-01 -3.3538e-01 -6.5751e-01 -2.0112e-01 -1.0297e+00\n",
      "   6.9195e-02 -6.1272e-01  1.1373e-01 -1.9547e-01 -2.1256e-01  4.9763e-02\n",
      "  -1.1619e+00 -6.4512e-02  5.3146e-01 -4.7384e-01 -6.8709e-01  1.3024e-01\n",
      "  -2.0899e+00 -4.1346e-01  3.0364e-01 -5.7448e-04 -1.8833e-01 -5.4779e-01\n",
      "  -3.2058e-01 -3.6704e-01 -1.4740e-01 -1.9044e-01 -4.7712e-01  4.8228e-02\n",
      "  -2.6215e-01 -5.9680e-01  8.0843e-02  2.7866e-01]\n",
      " [-2.6424e-01  2.2626e-01  8.2339e-01 -2.0665e-01  5.0187e-02 -3.7812e-01\n",
      "   2.2721e-01  9.1286e-01 -2.4134e-01 -2.5365e-01  1.2431e-01  9.3030e-02\n",
      "  -8.2057e-02 -4.8970e-02  1.4869e-01 -3.5864e-01  1.5002e-01  4.8099e-01\n",
      "  -2.5361e-01 -2.6409e-01  1.4916e-01 -3.2134e-01  1.0386e-02  5.6583e-01\n",
      "   1.8566e-01 -3.4025e-01 -2.1060e-01 -5.4901e-01  2.5186e-01  1.5121e-01\n",
      "  -7.1719e-01  1.3736e-01  4.4788e-01 -2.5483e-01 -6.2754e-02  6.2234e-01\n",
      "  -4.0210e-01 -2.8212e-01 -5.6098e-02 -2.2097e-01 -3.5708e-01 -2.7459e-01\n",
      "   5.0315e-01 -1.3496e-01 -1.4528e-01 -1.2431e-02  7.5285e-03 -6.0886e-01\n",
      "  -1.1221e-02 -8.1087e-01 -1.4036e-01 -5.8278e-01  5.7027e-02  1.0757e+00\n",
      "  -4.8716e-01 -3.0169e+00 -5.6784e-01 -1.7410e-01  1.8463e+00  6.2222e-01\n",
      "  -5.8392e-01  8.7285e-01 -3.2553e-01 -7.8565e-03  5.6621e-01  3.4026e-01\n",
      "  -2.4294e-01  5.9833e-01 -6.4817e-02 -3.4101e-01  4.7312e-01 -4.8022e-01\n",
      "  -4.5578e-01 -6.6012e-01 -7.1061e-02  7.0737e-02 -3.0658e-01 -1.5749e-01\n",
      "  -5.1771e-01 -8.6326e-02  6.6913e-01 -1.5034e-01 -3.4442e-01  1.2498e-01\n",
      "  -9.0054e-01 -3.8807e-01  1.4146e-01 -9.8806e-02  1.9738e-01 -3.0631e-01\n",
      "   1.8435e-01  4.4287e-01  1.2919e-01  3.1760e-01 -7.6439e-01  2.7220e-01\n",
      "   5.2238e-01  3.4128e-01  7.5776e-01  1.0251e-01]\n",
      " [ 1.4440e-01  2.3979e-01  9.6693e-01  3.1629e-01 -3.6064e-01 -8.7674e-01\n",
      "   9.8512e-02  3.1078e-01  4.7929e-01  2.7175e-01  3.0005e-01 -2.3732e-01\n",
      "  -3.1517e-01  1.7925e-01  6.1773e-01  5.9821e-01  4.9489e-01  3.4230e-01\n",
      "  -7.8034e-02  6.0212e-01  1.8683e-01  5.2070e-01 -1.2331e-01  4.8313e-01\n",
      "  -2.4117e-01  5.9696e-01  6.1078e-01 -8.4414e-01  2.7661e-01  6.8767e-02\n",
      "  -1.1388e+00  8.9544e-02  8.9842e-01  5.3788e-01  1.0841e-01 -1.0038e-01\n",
      "   1.2921e-01  1.1476e-01 -4.7400e-01 -8.0490e-01  9.6000e-01 -3.6602e-01\n",
      "  -4.3019e-01 -3.9808e-01 -9.6782e-02 -7.1184e-01 -3.1494e-01  8.2346e-01\n",
      "   4.2179e-01 -6.9205e-01 -1.4864e+00  2.9498e-01 -3.0875e-01 -4.9995e-01\n",
      "  -4.6490e-01 -4.4524e-01  8.1060e-01  1.4757e+00  5.3782e-01 -2.8271e-01\n",
      "  -4.5796e-02  1.4454e-01 -7.4485e-01  3.5495e-01 -4.0961e-01  3.5779e-01\n",
      "   4.0061e-01  3.7339e-01  7.2163e-01  4.0813e-01  2.6155e-01 -1.4239e-01\n",
      "  -2.0514e-02 -1.1106e+00 -4.7670e-01  3.7832e-01  8.9612e-01 -1.7323e-01\n",
      "  -5.0137e-01  2.2991e-01  1.5324e+00 -8.2032e-01 -1.0096e-01  4.5202e-01\n",
      "  -8.8639e-01  8.9056e-02 -1.9347e-01 -4.2253e-01  2.2429e-02  2.9444e-01\n",
      "   2.0747e-02  4.8935e-01  3.5991e-01  9.2758e-02 -2.2428e-01  6.0038e-01\n",
      "  -3.1850e-01 -7.2424e-01 -2.2632e-01 -3.0972e-02]\n",
      " [-3.8469e-01  9.9338e-01  1.3398e-01 -3.2708e-01 -7.7440e-02  1.7769e-01\n",
      "  -7.1985e-02  1.6160e-01 -1.3770e-01  5.1739e-02  1.5964e-01  1.6507e-02\n",
      "  -4.9616e-02 -5.3964e-01  2.4449e-01 -6.2066e-01 -3.4500e-01 -1.5009e-02\n",
      "   5.9399e-02  7.9348e-01  1.2096e+00 -9.4457e-02  1.4585e-01 -6.3804e-02\n",
      "   1.4680e-01 -5.0725e-01 -1.5582e-01 -6.9462e-01 -1.8542e-01 -2.0292e-01\n",
      "   1.1547e-02  3.9695e-01 -4.5813e-01 -1.9921e-01  3.2108e-01  5.4069e-01\n",
      "  -7.3385e-03  1.2096e-01 -7.7902e-01  4.2854e-01 -5.3546e-01 -5.8143e-01\n",
      "   1.4424e-01 -4.7396e-01 -2.0623e-01 -2.0815e-01  5.4938e-01 -5.1741e-01\n",
      "   9.0160e-02 -7.5701e-01 -6.3903e-02 -7.3684e-01 -9.7376e-02  1.2635e+00\n",
      "  -5.1026e-01 -2.5686e+00  4.7680e-01 -5.4214e-01  2.1144e+00  4.9177e-01\n",
      "   2.1146e-01  1.5787e+00 -2.8596e-01  5.1544e-02  4.9620e-01 -2.6324e-01\n",
      "   8.2709e-01  5.0339e-01  9.0994e-01 -2.8113e-01  2.0357e-02 -6.3306e-01\n",
      "  -3.3049e-01 -1.7052e-01  6.6252e-01 -5.5619e-02 -3.7653e-01 -1.5417e-01\n",
      "  -1.1648e+00 -1.5672e-01  1.2909e+00  1.2161e-01 -4.8802e-01  4.7592e-01\n",
      "  -1.5741e+00  1.7322e-01  6.2257e-01 -4.1003e-02 -5.2627e-01 -5.5419e-01\n",
      "   5.5319e-01  4.1970e-01 -4.1377e-01 -5.5962e-01 -8.1527e-01 -2.7972e-01\n",
      "  -8.5805e-01 -3.2359e-01  6.2028e-01  4.6397e-01]\n",
      " [-1.7615e-02  7.1409e-01  5.6899e-01 -8.7004e-01  2.4344e-01  1.2605e-02\n",
      "   1.1636e+00  2.6435e-01 -4.0081e-01 -8.5616e-01  1.8070e-02  4.7928e-01\n",
      "  -1.9203e-01  1.1651e+00  1.1201e-02  4.5673e-01 -1.8189e-01  3.6653e-02\n",
      "   1.2074e-01  1.5958e-01 -5.7728e-01  5.9417e-01 -7.3639e-01  1.0154e+00\n",
      "   4.6306e-01  4.2654e-01  2.3746e-01 -1.7230e-02  5.5253e-01 -3.0808e-01\n",
      "  -6.5263e-01 -2.1908e-01  1.0219e+00  1.9105e-02  4.5450e-01  3.2993e-02\n",
      "  -2.8162e-01  4.6132e-01 -1.0727e-01 -3.3626e-01  2.7620e-01 -7.6599e-02\n",
      "  -4.3141e-01  1.3312e-01  2.1826e-01 -2.6191e-01 -5.0655e-01  3.3324e-01\n",
      "   1.4159e-01 -5.0139e-02 -1.3387e+00  8.4875e-01  3.5564e-01 -2.9503e-01\n",
      "  -3.0308e-01 -7.2555e-01  4.6424e-01  3.0564e-01 -1.2002e-02 -3.2229e-01\n",
      "  -8.6294e-01  2.0429e-01 -6.6887e-01 -2.1808e-01  2.4976e-01  2.1191e-02\n",
      "  -4.9833e-01  2.2131e-01 -8.8580e-01 -3.4345e-01 -3.8110e-03 -4.3245e-01\n",
      "   9.6115e-02 -5.1509e-01 -3.8867e-01  9.5424e-01 -9.1293e-01 -5.2898e-01\n",
      "  -4.7135e-01 -8.4266e-02  7.5190e-01 -4.5923e-01 -4.6449e-01  8.8233e-03\n",
      "  -1.1421e+00 -3.5334e-01  3.5745e-01 -9.2065e-01 -9.1302e-01  6.1145e-01\n",
      "  -2.9105e-01  6.6216e-01  3.4592e-02  9.7191e-01 -5.6677e-02 -4.5511e-01\n",
      "   2.3668e-01  1.0498e+00 -2.8695e-01  4.9523e-01]\n",
      " [-2.4211e-01  5.0818e-01  1.7431e-01 -5.3048e-01  3.5010e-01  7.3978e-02\n",
      "  -2.2706e-01 -3.0032e-02  6.2771e-02 -1.8962e-01  1.4141e-01 -5.2596e-01\n",
      "   2.2941e-01  4.0335e-01  8.8935e-02 -2.3171e-01  2.0858e-01 -3.5073e-02\n",
      "  -3.9422e-01  4.2781e-01  2.3424e-01 -4.1532e-01  4.6025e-01  2.7109e-01\n",
      "   6.9915e-02 -4.3305e-01  9.1860e-02 -6.1606e-01 -2.3359e-01  2.6862e-01\n",
      "   2.2462e-01  2.3171e-01 -6.4934e-01  6.9331e-02  2.4512e-01  5.9737e-01\n",
      "   1.9781e-01  1.2867e-01 -3.2702e-01 -6.0648e-02 -8.7321e-01 -4.0892e-01\n",
      "   5.8644e-02 -3.6917e-01 -1.6837e-01  3.0640e-01 -3.8920e-02 -1.2069e-01\n",
      "  -3.9722e-01 -3.6063e-01 -1.0863e-01  3.5632e-03  2.5545e-02  9.0860e-01\n",
      "  -1.1305e-01 -1.7753e+00  4.0640e-02 -3.9332e-01  2.0438e+00  1.0871e+00\n",
      "  -5.3628e-01  1.3211e+00  4.0919e-01  5.7779e-01  8.2953e-01 -5.6870e-02\n",
      "   5.9288e-01  4.0324e-01  8.2516e-01 -3.2087e-01 -6.8111e-01 -6.3115e-01\n",
      "  -1.0051e-01 -4.4106e-01  2.5615e-01  3.1669e-02 -7.9954e-02 -2.7123e-01\n",
      "  -1.1283e+00  1.3381e-01  1.1280e+00  7.5743e-02 -1.7830e-01  3.4094e-01\n",
      "  -2.2092e+00 -5.4769e-02 -3.2665e-01  1.4640e-01  6.6519e-02 -3.9811e-01\n",
      "  -3.2919e-01 -3.2736e-01 -2.1051e-01 -5.5697e-02 -1.2548e+00  2.0434e-02\n",
      "  -1.0430e+00 -4.4059e-01  1.0769e+00  3.2406e-01]\n",
      " [-1.1619e-01  4.5447e-01 -6.9216e-01  3.4580e-02  2.6348e-01 -3.8139e-01\n",
      "  -2.2790e-01  3.7233e-01 -2.0579e-01  2.9020e-01  1.2114e-01 -4.2729e-01\n",
      "   5.5573e-01 -9.4286e-02 -4.9967e-01 -2.9478e-01  7.4109e-01  2.5191e-01\n",
      "  -2.7468e-01  2.3191e-01  3.8204e-03  4.5252e-02  2.4970e-01 -4.1579e-01\n",
      "   3.1307e-01 -5.8496e-01 -3.2739e-01 -6.6189e-01  1.4909e-01 -2.5771e-01\n",
      "  -9.4858e-01  4.1809e-01 -2.9538e-01 -4.2711e-02 -6.9970e-01  5.7892e-01\n",
      "  -6.9271e-02 -3.9633e-02 -5.6463e-03 -2.9616e-01 -5.7448e-01  1.6010e-01\n",
      "  -1.0671e-01  1.0096e-01 -4.2956e-01 -2.7785e-01 -3.0017e-01 -6.9537e-01\n",
      "   1.7965e-01 -4.6723e-01  1.2511e-01 -2.9022e-02 -1.5974e-01  1.4217e+00\n",
      "  -2.6224e-01 -2.3719e+00 -1.1917e-01 -5.8262e-01  1.5548e+00  4.2212e-01\n",
      "   8.4633e-02  1.1385e+00 -3.1226e-01 -5.0738e-02  1.0936e+00 -1.4370e-03\n",
      "   4.4641e-01  3.4625e-01  4.3964e-01 -3.8941e-01  2.7082e-01  8.0626e-02\n",
      "  -5.6481e-02 -4.1097e-01  5.6420e-01 -1.5158e-01 -1.4931e-01  1.7199e-01\n",
      "  -6.1495e-01 -1.5822e-01  3.2818e-01  4.9756e-01 -3.2947e-01  1.6222e-01\n",
      "  -2.3063e+00  4.0681e-01  2.7702e-01 -3.7002e-01 -8.0969e-01 -7.6256e-01\n",
      "   9.1109e-02 -6.1473e-01  2.5286e-01  5.9980e-02 -2.1977e-01  7.2382e-03\n",
      "  -3.3877e-01 -5.4737e-01  4.8822e-01  3.2246e-01]\n",
      " [-7.1766e-01  8.0871e-01  3.1868e-01 -5.3589e-01 -3.1998e-01  1.8929e-01\n",
      "  -2.3241e-01  4.4233e-01  2.5649e-01 -3.2093e-01 -1.6951e-01  1.4993e-01\n",
      "   5.5681e-01  3.3992e-01  2.8335e-02 -3.8295e-01  4.3366e-01  7.3026e-01\n",
      "  -7.9863e-01  2.9540e-01  1.7078e-02 -3.9545e-01  1.9967e-01  8.1727e-02\n",
      "   1.8943e-01  9.5973e-02 -3.3138e-02 -6.9888e-01  4.1562e-01 -6.7422e-01\n",
      "  -5.9873e-02  1.2300e+00 -3.1391e-01  1.5313e-01  8.2508e-01  4.9345e-01\n",
      "  -5.1686e-02  3.1035e-01  2.5147e-01 -3.6228e-01 -1.4969e-01 -3.9609e-01\n",
      "  -7.3853e-01 -1.0716e+00 -2.1775e-01  2.3018e-01  7.8188e-02 -4.8584e-01\n",
      "  -8.2414e-02 -1.0405e+00  4.4389e-01 -2.9640e-01  3.6505e-02  1.2115e+00\n",
      "   5.0287e-01 -2.2662e+00 -7.3575e-02  1.0925e-02  1.7266e+00  6.3332e-01\n",
      "  -2.3215e-01  1.2603e+00 -4.3585e-01 -8.2693e-02  1.1903e+00  3.4009e-01\n",
      "   5.9365e-01  2.0098e-01  1.0160e-01 -1.1757e+00 -1.1870e-01 -5.9569e-01\n",
      "   3.4427e-01 -4.8687e-01  3.4953e-01 -4.4521e-01 -1.3131e-01 -1.9316e-01\n",
      "  -5.5304e-01  7.5953e-02  6.8930e-01 -2.6706e-01 -1.1425e+00 -4.2210e-01\n",
      "  -1.9038e+00  2.8733e-02  7.9527e-01 -5.1330e-02 -2.8824e-02 -3.5704e-01\n",
      "  -7.2769e-01  1.9074e-01 -2.6097e-02 -4.8544e-01 -2.2500e-01  2.5487e-02\n",
      "   2.7732e-01 -1.0023e+00  8.5880e-01  2.8583e-01]]\n",
      "[[-0.017615    0.71409     0.56899    -0.87004     0.24344     0.012605\n",
      "   1.1636      0.26435    -0.40081    -0.85616     0.01807     0.47928\n",
      "  -0.19203     1.1651      0.011201    0.45673    -0.18189     0.036653\n",
      "   0.12074     0.15958    -0.57728     0.59417    -0.73639     1.0154\n",
      "   0.46306     0.42654     0.23746    -0.01723     0.55253    -0.30808\n",
      "  -0.65263    -0.21908     1.0219      0.019105    0.4545      0.032993\n",
      "  -0.28162     0.46132    -0.10727    -0.33626     0.2762     -0.076599\n",
      "  -0.43141     0.13312     0.21826    -0.26191    -0.50655     0.33324\n",
      "   0.14159    -0.050139   -1.3387      0.84875     0.35564    -0.29503\n",
      "  -0.30308    -0.72555     0.46424     0.30564    -0.012002   -0.32229\n",
      "  -0.86294     0.20429    -0.66887    -0.21808     0.24976     0.021191\n",
      "  -0.49833     0.22131    -0.8858     -0.34345    -0.003811   -0.43245\n",
      "   0.096115   -0.51509    -0.38867     0.95424    -0.91293    -0.52898\n",
      "  -0.47135    -0.084266    0.7519     -0.45923    -0.46449     0.0088233\n",
      "  -1.1421     -0.35334     0.35745    -0.92065    -0.91302     0.61145\n",
      "  -0.29105     0.66216     0.034592    0.97191    -0.056677   -0.45511\n",
      "   0.23668     1.0498     -0.28695     0.49523   ]\n",
      " [ 0.1444      0.23979     0.96693     0.31629    -0.36064    -0.87674\n",
      "   0.098512    0.31078     0.47929     0.27175     0.30005    -0.23732\n",
      "  -0.31517     0.17925     0.61773     0.59821     0.49489     0.3423\n",
      "  -0.078034    0.60212     0.18683     0.5207     -0.12331     0.48313\n",
      "  -0.24117     0.59696     0.61078    -0.84414     0.27661     0.068767\n",
      "  -1.1388      0.089544    0.89842     0.53788     0.10841    -0.10038\n",
      "   0.12921     0.11476    -0.474      -0.8049      0.96       -0.36602\n",
      "  -0.43019    -0.39808    -0.096782   -0.71184    -0.31494     0.82346\n",
      "   0.42179    -0.69205    -1.4864      0.29498    -0.30875    -0.49995\n",
      "  -0.4649     -0.44524     0.8106      1.4757      0.53782    -0.28271\n",
      "  -0.045796    0.14454    -0.74485     0.35495    -0.40961     0.35779\n",
      "   0.40061     0.37339     0.72163     0.40813     0.26155    -0.14239\n",
      "  -0.020514   -1.1106     -0.4767      0.37832     0.89612    -0.17323\n",
      "  -0.50137     0.22991     1.5324     -0.82032    -0.10096     0.45202\n",
      "  -0.88639     0.089056   -0.19347    -0.42253     0.022429    0.29444\n",
      "   0.020747    0.48935     0.35991     0.092758   -0.22428     0.60038\n",
      "  -0.3185     -0.72424    -0.22632    -0.030972  ]\n",
      " [ 0.1419971   0.73428562 -1.15821069 -0.49806953 -0.53742935  0.90465624\n",
      "  -1.03449088 -0.13735645  0.13948162  1.65126726  0.18866657  0.19629534\n",
      "   0.77956031  0.0075716  -0.05643578  1.37549447  0.8570602   0.15188792\n",
      "  -0.94714546 -0.38188497  0.28842305 -0.09815966 -1.10909519 -1.27512824\n",
      "  -0.02593    -0.21074027 -0.26250746 -0.57631638  0.61753554  0.5472804\n",
      "   0.34420829  0.11722675  0.05244357 -0.99771847  1.12262784 -0.9573582\n",
      "  -1.3382065  -0.64955612  1.26709299 -0.341034    0.19441688 -1.08304449\n",
      "   0.04321723 -0.63290316 -0.7253175   0.71644005 -0.50400722 -1.29276535\n",
      "  -0.23588034 -0.23954916  0.87140413  0.30164092 -0.19002648  0.08705411\n",
      "  -0.49569231 -0.08117269 -0.02487419  0.43019115 -0.15495678  0.02675045\n",
      "  -0.87959813 -0.04246752 -0.79025429  0.54359298  0.20508585 -0.37687986\n",
      "  -0.09879755  0.73336703  0.46591326  0.93102533  0.91249702  0.48884855\n",
      "  -0.38812195 -1.24604655  0.8553823   0.73646001  0.12801275 -0.39268351\n",
      "   1.59105177  1.99217968 -0.24003234  0.31647423  0.30656573  0.87010968\n",
      "  -0.42944431  1.09883962 -0.48076236  0.09717001  0.31259101 -0.1496562\n",
      "   0.83135967 -0.31229702 -0.35623587 -0.26324192 -0.36627372 -0.64410336\n",
      "   0.61547037 -0.10958124  0.47820954 -0.46360311]]\n"
     ]
    }
   ],
   "source": [
    "# Testing vsms\n",
    "test_1 = create_vsm(['hi', 'bye', 'can', 'not', 'more', 'words', 'next', 'other', 'work', 'bye', 'can', 'not', 'more', 'words', 'next', 'other', 'work'], embed_size=100)\n",
    "test_2 = create_vsm(['hi', 'bye', 'askfdklsd'], embed_size=100)\n",
    "test_3 = create_vsm(['lkadsfj', 'hello', 'be'], embed_size=50)\n",
    "test_4 = create_vsm(['hi', 'askfdklsd', 'bye'], embed_size=100)\n",
    "#test_5 = create_vsm(['hi'], embed_size = 60)\n",
    "print(test_1)\n",
    "print(test_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = load_glove('glove.6B/glove.6B.100d.txt')\n",
    "randomly_sample(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "ls = []\n",
    "ls.append(np.array([4,5,6]))\n",
    "ls.append([1,2,3])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[4, 5, 6],\n",
       "       [1, 2, 3]])"
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.array(ls)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [],
   "source": [
    "import codecs\n",
    "from collections import defaultdict\n",
    "import itertools\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import random\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.manifold import TSNE\n",
    "import scipy\n",
    "import scipy.spatial.distance\n",
    "import sys\n",
    "def lsa(df, k=100):\n",
    "    \"\"\"Latent Semantic Analysis using pure scipy.\n",
    "    Parameters\n",
    "    ----------\n",
    "    df : pd.DataFrame\n",
    "       The matrix to operate on.\n",
    "    k : int (default: 100)\n",
    "        Number of dimensions to truncate to.\n",
    "    Returns\n",
    "    -------\n",
    "    pd.DataFrame\n",
    "        The SVD-reduced version of `df` with dimension (m x k), where\n",
    "        m is the rowcount of mat and `k` is either the user-supplied\n",
    "        k or the column count of `mat`, whichever is smaller.\n",
    "    \"\"\"\n",
    "    rowmat, singvals, colmat = np.linalg.svd(df, full_matrices=False)\n",
    "    singvals = np.diag(singvals)\n",
    "    trunc = np.dot(rowmat[:, 0:k], singvals[0:k, 0:k])\n",
    "    return pd.DataFrame(trunc, index=df.index)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_vsm(corpus, embed_size=50):\n",
    "    lsa()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
